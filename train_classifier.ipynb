{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "from datasets import BadNetsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleansed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleansedDataset(VisionDataset):\n",
    "\n",
    "    def __init__(self, poison_dataset: VisionDataset, cleansed_labels_name: str, strategy: str = \"remove\"):\n",
    "        self.poison_dataset = poison_dataset\n",
    "        self.poison_indices = list(range(len(self.poison_dataset)))\n",
    "        \n",
    "        with open(f\"./cleansed_labels/{cleansed_labels_name}.pkl\", 'rb') as f:\n",
    "            self.predicted_labels = pickle.load(f)\n",
    "\n",
    "        assert strategy in [\"relabel\", \"remove\"]\n",
    "        self.strategy = strategy\n",
    "\n",
    "        poison_labels = [label for _, label in self.poison_dataset]\n",
    "        if self.strategy == \"remove\":\n",
    "            self.indices = [index for index in self.poison_indices if poison_labels[index]==self.predicted_labels[index]]\n",
    "        elif self.strategy == \"relabel\":\n",
    "            self.indices = self.poison_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if index > len(self):\n",
    "            return IndexError()\n",
    "        while index not in self.indices:\n",
    "            index += 1\n",
    "\n",
    "        item = self.poison_dataset[index][0]\n",
    "        label = self.predicted_labels[index]\n",
    "\n",
    "        return item, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='D:/Datasets', train=True, download=True)\n",
    "train_poison_dataset = BadNetsDataset(train_dataset, 0, \"triggers/trigger_white.png\", seed=1, transform=transform_train)\n",
    "train_cleansed_dataset = CleansedDataset(train_poison_dataset, \"SimCLR_300_cleanse_train\", strategy=\"remove\")\n",
    "trainloader = DataLoader(train_cleansed_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='D:/Datasets', train=False, download=True)\n",
    "test_poison_dataset = BadNetsDataset(test_dataset, 0, \"triggers/trigger_white.png\", seed=1, transform=transform_test)\n",
    "test_cleansed_dataset = CleansedDataset(test_poison_dataset, \"SimCLR_300_cleanse_test\", strategy=\"remove\")\n",
    "testloader = DataLoader(test_cleansed_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Resnet-18 classifier on the cleansed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, epoch, name):\n",
    "    out = os.path.join('./saved_models/', name)\n",
    "\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'epoch': epoch\n",
    "                }, out)\n",
    "\n",
    "    print(f\"\\tSaved model, optimizer, scheduler and epoch info to {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "\n",
    "load_checkpoint = False\n",
    "checkpoint_name = \"Resnet18_10.pt\"\n",
    "\n",
    "if load_checkpoint:\n",
    "    out = os.path.join('./saved_models/', checkpoint_name)\n",
    "    checkpoint = torch.load(out, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, dataloader, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for _, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        if len(targets.shape)>1:\n",
    "            targets = targets.squeeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    return train_loss, acc\n",
    "\n",
    "def test(epoch, model, dataloader, criterion, optimizer, save=False):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            if len(targets.shape)>1:\n",
    "                targets = targets.squeeze(1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        if save: save_model(model, optimizer, scheduler, epoch, f\"Resnet-18.pt\")\n",
    "        best_acc = acc\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 252.01508277654648 Test Loss: 252.01508277654648\n",
      "\tTraining Acc: 68.28819279796937 Test Acc: 64.8571855839689\n",
      "\tTime Taken: 0.7757977883021037 minutes\n",
      "Epoch [2/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 204.7516794502735 Test Loss: 204.7516794502735\n",
      "\tTraining Acc: 74.58090429834593 Test Acc: 73.27650665470316\n",
      "\tTime Taken: 0.7692479968070984 minutes\n",
      "Epoch [3/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 164.9495508670807 Test Loss: 164.9495508670807\n",
      "\tTraining Acc: 79.49569049677834 Test Acc: 77.5235531628533\n",
      "\tTime Taken: 0.7667462627092997 minutes\n",
      "Epoch [4/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 141.45508459210396 Test Loss: 141.45508459210396\n",
      "\tTraining Acc: 82.22085855345736 Test Acc: 80.84342754598475\n",
      "\tTime Taken: 0.7692098061243693 minutes\n",
      "Epoch [5/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 120.66096869111061 Test Loss: 120.66096869111061\n",
      "\tTraining Acc: 85.11896460349782 Test Acc: 82.24914012262599\n",
      "\tTime Taken: 0.7697420199712117 minutes\n",
      "Epoch [6/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 100.69454601407051 Test Loss: 100.69454601407051\n",
      "\tTraining Acc: 87.50383531840116 Test Acc: 85.21010916704053\n",
      "\tTime Taken: 0.7848929286003112 minutes\n",
      "Epoch [7/100]\t\n",
      "\tTraining Loss: 90.87104284763336 Test Loss: 90.87104284763336\n",
      "\tTraining Acc: 88.8148168809796 Test Acc: 83.93898609241812\n",
      "\tTime Taken: 0.7800106724103292 minutes\n",
      "Epoch [8/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 87.3627323359251 Test Loss: 87.3627323359251\n",
      "\tTraining Acc: 89.124431675546 Test Acc: 88.00657993120981\n",
      "\tTime Taken: 0.780727485815684 minutes\n",
      "Epoch [9/100]\t\n",
      "\tTraining Loss: 76.0778112411499 Test Loss: 76.0778112411499\n",
      "\tTraining Acc: 90.72271345290228 Test Acc: 84.13339315088979\n",
      "\tTime Taken: 0.7663362542788188 minutes\n",
      "Epoch [10/100]\t\n",
      "\tTraining Loss: 72.78985938429832 Test Loss: 72.78985938429832\n",
      "\tTraining Acc: 90.95701654068228 Test Acc: 87.61776581426649\n",
      "\tTime Taken: 0.7663755496342977 minutes\n",
      "Epoch [11/100]\t\n",
      "\tTraining Loss: 71.50294294208288 Test Loss: 71.50294294208288\n",
      "\tTraining Acc: 91.15226911383225 Test Acc: 87.57290264692688\n",
      "\tTime Taken: 0.7661849776903789 minutes\n",
      "Epoch [12/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 65.21604114770889 Test Loss: 65.21604114770889\n",
      "\tTraining Acc: 91.79381328275362 Test Acc: 88.05144309854943\n",
      "\tTime Taken: 0.7664783239364624 minutes\n",
      "Epoch [13/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 63.04920920729637 Test Loss: 63.04920920729637\n",
      "\tTraining Acc: 92.09506010989931 Test Acc: 88.81411694332286\n",
      "\tTime Taken: 0.7680049498875936 minutes\n",
      "Epoch [14/100]\t\n",
      "\tTraining Loss: 61.26346232742071 Test Loss: 61.26346232742071\n",
      "\tTraining Acc: 92.42977880672784 Test Acc: 85.55406011664424\n",
      "\tTime Taken: 0.7654221216837566 minutes\n",
      "Epoch [15/100]\t\n",
      "\tTraining Loss: 61.466511242091656 Test Loss: 61.466511242091656\n",
      "\tTraining Acc: 92.46603999888427 Test Acc: 77.28428293704202\n",
      "\tTime Taken: 0.7750951449076334 minutes\n",
      "Epoch [16/100]\t\n",
      "\tTraining Loss: 63.17811889946461 Test Loss: 63.17811889946461\n",
      "\tTraining Acc: 92.26241945831357 Test Acc: 85.98773740092717\n",
      "\tTime Taken: 0.7648805459340413 minutes\n",
      "Epoch [17/100]\t\n",
      "\tTraining Loss: 59.42378630489111 Test Loss: 59.42378630489111\n",
      "\tTraining Acc: 92.72265766645282 Test Acc: 85.91296545536115\n",
      "\tTime Taken: 0.7651838302612305 minutes\n",
      "Epoch [18/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 57.329048067331314 Test Loss: 57.329048067331314\n",
      "\tTraining Acc: 93.07132297564921 Test Acc: 88.9038432780021\n",
      "\tTime Taken: 0.7660752654075622 minutes\n",
      "Epoch [19/100]\t\n",
      "\tTraining Loss: 55.39442798495293 Test Loss: 55.39442798495293\n",
      "\tTraining Acc: 93.30562606342919 Test Acc: 87.27381486466278\n",
      "\tTime Taken: 0.7636128465334574 minutes\n",
      "Epoch [20/100]\t\n",
      "\tTraining Loss: 55.37483171373606 Test Loss: 55.37483171373606\n",
      "\tTraining Acc: 93.32236199827062 Test Acc: 87.15417975175714\n",
      "\tTime Taken: 0.7667823235193888 minutes\n",
      "Epoch [21/100]\t\n",
      "\tTraining Loss: 56.672077253460884 Test Loss: 56.672077253460884\n",
      "\tTraining Acc: 93.11595213522635 Test Acc: 83.59503514281441\n",
      "\tTime Taken: 0.7657412966092427 minutes\n",
      "Epoch [22/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 58.517637982964516 Test Loss: 58.517637982964516\n",
      "\tTraining Acc: 92.80912666313353 Test Acc: 89.63660834454913\n",
      "\tTime Taken: 0.7660235563913981 minutes\n",
      "Epoch [23/100]\t\n",
      "\tTraining Loss: 53.82439302653074 Test Loss: 53.82439302653074\n",
      "\tTraining Acc: 93.47019608936989 Test Acc: 86.61582174368176\n",
      "\tTime Taken: 0.766040559609731 minutes\n",
      "Epoch [24/100]\t\n",
      "\tTraining Loss: 54.977630861103535 Test Loss: 54.977630861103535\n",
      "\tTraining Acc: 93.36699115784776 Test Acc: 83.38567369522956\n",
      "\tTime Taken: 0.7664506316184998 minutes\n",
      "Epoch [25/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 60.317321725189686 Test Loss: 60.317321725189686\n",
      "\tTraining Acc: 92.67244986192854 Test Acc: 91.05727531030358\n",
      "\tTime Taken: 0.7663820505142211 minutes\n",
      "Epoch [26/100]\t\n",
      "\tTraining Loss: 47.16730561852455 Test Loss: 47.16730561852455\n",
      "\tTraining Acc: 94.17868399765698 Test Acc: 83.20622102587109\n",
      "\tTime Taken: 0.7650993307431538 minutes\n",
      "Epoch [27/100]\t\n",
      "\tTraining Loss: 51.93006832152605 Test Loss: 51.93006832152605\n",
      "\tTraining Acc: 93.788178851357 Test Acc: 88.15612382234185\n",
      "\tTime Taken: 0.766540797551473 minutes\n",
      "Epoch [28/100]\t\n",
      "\tTraining Loss: 49.526495553553104 Test Loss: 49.526495553553104\n",
      "\tTraining Acc: 93.963906167192 Test Acc: 83.77448781217288\n",
      "\tTime Taken: 0.7661604364713033 minutes\n",
      "Epoch [29/100]\t\n",
      "\tTraining Loss: 49.93220015615225 Test Loss: 49.93220015615225\n",
      "\tTraining Acc: 94.00853532676913 Test Acc: 89.80110662479437\n",
      "\tTime Taken: 0.7647541642189026 minutes\n",
      "Epoch [30/100]\t\n",
      "\tTraining Loss: 48.86335329711437 Test Loss: 48.86335329711437\n",
      "\tTraining Acc: 93.90811971772057 Test Acc: 89.05338716913414\n",
      "\tTime Taken: 0.7667519489924113 minutes\n",
      "Epoch [31/100]\t\n",
      "\tTraining Loss: 48.44197151437402 Test Loss: 48.44197151437402\n",
      "\tTraining Acc: 94.24283841454911 Test Acc: 88.45521160460595\n",
      "\tTime Taken: 0.7655089696248373 minutes\n",
      "Epoch [32/100]\t\n",
      "\tTraining Loss: 49.55195562168956 Test Loss: 49.55195562168956\n",
      "\tTraining Acc: 93.95274887729771 Test Acc: 90.66846119336026\n",
      "\tTime Taken: 0.7664647181828816 minutes\n",
      "Epoch [33/100]\t\n",
      "\tTraining Loss: 44.944549184292555 Test Loss: 44.944549184292555\n",
      "\tTraining Acc: 94.60545033611336 Test Acc: 86.7354568565874\n",
      "\tTime Taken: 0.7657457709312439 minutes\n",
      "Epoch [34/100]\t\n",
      "\tTraining Loss: 52.029449585825205 Test Loss: 52.029449585825205\n",
      "\tTraining Acc: 93.64313408273131 Test Acc: 86.64573052190818\n",
      "\tTime Taken: 0.7659322460492451 minutes\n",
      "Epoch [35/100]\t\n",
      "\tTraining Loss: 46.139815993607044 Test Loss: 46.139815993607044\n",
      "\tTraining Acc: 94.49108811469694 Test Acc: 89.93569612681323\n",
      "\tTime Taken: 0.7660578052202861 minutes\n",
      "Epoch [36/100]\t\n",
      "\tTraining Loss: 42.57379173487425 Test Loss: 42.57379173487425\n",
      "\tTraining Acc: 94.85648935873476 Test Acc: 86.15223568117243\n",
      "\tTime Taken: 0.7641665617624919 minutes\n",
      "Epoch [37/100]\t\n",
      "\tTraining Loss: 47.82805248349905 Test Loss: 47.82805248349905\n",
      "\tTraining Acc: 94.27909960670553 Test Acc: 83.35576491700314\n",
      "\tTime Taken: 0.7654764731725057 minutes\n",
      "Epoch [38/100]\t\n",
      "\tTraining Loss: 46.8891935236752 Test Loss: 46.8891935236752\n",
      "\tTraining Acc: 94.39625115059552 Test Acc: 88.85898011066249\n",
      "\tTime Taken: 0.7655117233594259 minutes\n",
      "Epoch [39/100]\t\n",
      "\tTraining Loss: 47.10906624421477 Test Loss: 47.10906624421477\n",
      "\tTraining Acc: 94.25678502691696 Test Acc: 88.79916255420966\n",
      "\tTime Taken: 0.7644772291183471 minutes\n",
      "Epoch [40/100]\t\n",
      "\tTraining Loss: 42.694617073982954 Test Loss: 42.694617073982954\n",
      "\tTraining Acc: 94.71144459010907 Test Acc: 90.26469268730372\n",
      "\tTime Taken: 0.7650362730026246 minutes\n",
      "Epoch [41/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 38.89410185627639 Test Loss: 38.89410185627639\n",
      "\tTraining Acc: 95.18562941061616 Test Acc: 92.74712128009571\n",
      "\tTime Taken: 0.7670489947001139 minutes\n",
      "Epoch [42/100]\t\n",
      "\tTraining Loss: 39.12777836620808 Test Loss: 39.12777836620808\n",
      "\tTraining Acc: 95.29720230955901 Test Acc: 90.72827874981307\n",
      "\tTime Taken: 0.7665875792503357 minutes\n",
      "Epoch [43/100]\t\n",
      "\tTraining Loss: 40.64288242533803 Test Loss: 40.64288242533803\n",
      "\tTraining Acc: 95.14378957351259 Test Acc: 83.59503514281441\n",
      "\tTime Taken: 0.7644982854525249 minutes\n",
      "Epoch [44/100]\t\n",
      "\tTraining Loss: 50.17475261725485 Test Loss: 50.17475261725485\n",
      "\tTraining Acc: 93.98622074698056 Test Acc: 89.93569612681323\n",
      "\tTime Taken: 0.7772119204203288 minutes\n",
      "Epoch [45/100]\t\n",
      "\tTraining Loss: 39.98495837301016 Test Loss: 39.98495837301016\n",
      "\tTraining Acc: 95.12147499372402 Test Acc: 89.24779422760581\n",
      "\tTime Taken: 0.7644713481267293 minutes\n",
      "Epoch [46/100]\t\n",
      "\tTraining Loss: 44.041543597355485 Test Loss: 44.041543597355485\n",
      "\tTraining Acc: 94.70586594516192 Test Acc: 88.66457305219082\n",
      "\tTime Taken: 0.7631445924441019 minutes\n",
      "Epoch [47/100]\t\n",
      "\tTraining Loss: 38.863552305847406 Test Loss: 38.863552305847406\n",
      "\tTraining Acc: 95.40319656355472 Test Acc: 87.16913414087034\n",
      "\tTime Taken: 0.763777514298757 minutes\n",
      "Epoch [48/100]\t\n",
      "\tTraining Loss: 49.46627101302147 Test Loss: 49.46627101302147\n",
      "\tTraining Acc: 94.06711109871412 Test Acc: 91.23672797966204\n",
      "\tTime Taken: 0.764059591293335 minutes\n",
      "Epoch [49/100]\t\n",
      "\tTraining Loss: 39.3714695982635 Test Loss: 39.3714695982635\n",
      "\tTraining Acc: 95.32230621182114 Test Acc: 89.84596979213399\n",
      "\tTime Taken: 0.7665461381276448 minutes\n",
      "Epoch [50/100]\t\n",
      "\tTraining Loss: 48.98670194670558 Test Loss: 48.98670194670558\n",
      "\tTraining Acc: 94.20099857744553 Test Acc: 90.57873485868102\n",
      "\tTime Taken: 0.7653036793073018 minutes\n",
      "Epoch [51/100]\t\n",
      "\tTraining Loss: 40.17179813794792 Test Loss: 40.17179813794792\n",
      "\tTraining Acc: 95.19957602298402 Test Acc: 91.4610438163601\n",
      "\tTime Taken: 0.7649993658065796 minutes\n",
      "Epoch [52/100]\t\n",
      "\tTraining Loss: 39.08565892651677 Test Loss: 39.08565892651677\n",
      "\tTraining Acc: 95.11868567125045 Test Acc: 89.14311350381337\n",
      "\tTime Taken: 0.7641644914944966 minutes\n",
      "Epoch [53/100]\t\n",
      "\tTraining Loss: 37.94813747704029 Test Loss: 37.94813747704029\n",
      "\tTraining Acc: 95.39761791860757 Test Acc: 89.41229250785105\n",
      "\tTime Taken: 0.7640321731567383 minutes\n",
      "Epoch [54/100]\t\n",
      "\tTraining Loss: 38.94163813441992 Test Loss: 38.94163813441992\n",
      "\tTraining Acc: 95.31393824440043 Test Acc: 88.18603260056827\n",
      "\tTime Taken: 0.7644676446914673 minutes\n",
      "Epoch [55/100]\t\n",
      "\tTraining Loss: 43.93477447703481 Test Loss: 43.93477447703481\n",
      "\tTraining Acc: 94.69749797774121 Test Acc: 91.28159114700165\n",
      "\tTime Taken: 0.7641186038653056 minutes\n",
      "Epoch [56/100]\t\n",
      "\tTraining Loss: 37.42270151153207 Test Loss: 37.42270151153207\n",
      "\tTraining Acc: 95.56497726702185 Test Acc: 91.53581576192613\n",
      "\tTime Taken: 0.7651293873786926 minutes\n",
      "Epoch [57/100]\t\n",
      "\tTraining Loss: 48.0453676097095 Test Loss: 48.0453676097095\n",
      "\tTraining Acc: 94.22889180218125 Test Acc: 91.84985793330343\n",
      "\tTime Taken: 0.7662688493728638 minutes\n",
      "Epoch [58/100]\t\n",
      "\tTraining Loss: 38.79623759910464 Test Loss: 38.79623759910464\n",
      "\tTraining Acc: 95.29162366461186 Test Acc: 92.53775983251084\n",
      "\tTime Taken: 0.7642681837081909 minutes\n",
      "Epoch [59/100]\t\n",
      "\tTraining Loss: 38.945147816091776 Test Loss: 38.945147816091776\n",
      "\tTraining Acc: 95.26094111740258 Test Acc: 89.45715567519066\n",
      "\tTime Taken: 0.7658722201983134 minutes\n",
      "Epoch [60/100]\t\n",
      "\tTraining Loss: 37.28995732776821 Test Loss: 37.28995732776821\n",
      "\tTraining Acc: 95.45619369055257 Test Acc: 90.54882608045462\n",
      "\tTime Taken: 0.7648347377777099 minutes\n",
      "Epoch [61/100]\t\n",
      "\tTraining Loss: 32.52946279942989 Test Loss: 32.52946279942989\n",
      "\tTraining Acc: 96.14794566399821 Test Acc: 90.75818752803949\n",
      "\tTime Taken: 0.7661134521166484 minutes\n",
      "Epoch [62/100]\t\n",
      "\tTraining Loss: 38.40382558852434 Test Loss: 38.40382558852434\n",
      "\tTraining Acc: 95.36414604892471 Test Acc: 90.99745775385075\n",
      "\tTime Taken: 0.7657635490099589 minutes\n",
      "Epoch [63/100]\t\n",
      "\tTraining Loss: 35.19917672500014 Test Loss: 35.19917672500014\n",
      "\tTraining Acc: 95.78254441996039 Test Acc: 89.18797667115298\n",
      "\tTime Taken: 0.7653794765472413 minutes\n",
      "Epoch [64/100]\t\n",
      "\tTraining Loss: 34.93049930408597 Test Loss: 34.93049930408597\n",
      "\tTraining Acc: 95.75744051769826 Test Acc: 90.66846119336026\n",
      "\tTime Taken: 0.7646511395772299 minutes\n",
      "Epoch [65/100]\t\n",
      "\tTraining Loss: 32.235857451334596 Test Loss: 32.235857451334596\n",
      "\tTraining Acc: 96.1005271819475 Test Acc: 91.16195603409601\n",
      "\tTime Taken: 0.7642864108085632 minutes\n",
      "Epoch [66/100]\t\n",
      "\tTraining Loss: 33.941954512149096 Test Loss: 33.941954512149096\n",
      "\tTraining Acc: 95.93595715600681 Test Acc: 91.59563331837894\n",
      "\tTime Taken: 0.7647408246994019 minutes\n",
      "Epoch [67/100]\t\n",
      "\tTraining Loss: 36.18221155554056 Test Loss: 36.18221155554056\n",
      "\tTraining Acc: 95.59008116928398 Test Acc: 89.72633467922836\n",
      "\tTime Taken: 0.7698935349782308 minutes\n",
      "Epoch [68/100]\t\n",
      "\tTraining Loss: 31.42690110206604 Test Loss: 31.42690110206604\n",
      "\tTraining Acc: 96.3041477225182 Test Acc: 91.1320472558696\n",
      "\tTime Taken: 0.7553707758585612 minutes\n",
      "Epoch [69/100]\t\n",
      "\tTraining Loss: 38.403128903359175 Test Loss: 38.403128903359175\n",
      "\tTraining Acc: 95.42551114334329 Test Acc: 90.10019440705847\n",
      "\tTime Taken: 0.7552071452140808 minutes\n",
      "Epoch [70/100]\t\n",
      "\tTraining Loss: 33.765891406685114 Test Loss: 33.765891406685114\n",
      "\tTraining Acc: 95.98337563805751 Test Acc: 88.00657993120981\n",
      "\tTime Taken: 0.7563666939735413 minutes\n",
      "Epoch [71/100]\t\n",
      "\tTraining Loss: 33.83829326368868 Test Loss: 33.83829326368868\n",
      "\tTraining Acc: 96.01126886279323 Test Acc: 91.4759982054733\n",
      "\tTime Taken: 0.7637267271677654 minutes\n",
      "Epoch [72/100]\t\n",
      "\tTraining Loss: 32.517040533944964 Test Loss: 32.517040533944964\n",
      "\tTraining Acc: 96.11168447184178 Test Acc: 88.6197098848512\n",
      "\tTime Taken: 0.7644493897755941 minutes\n",
      "Epoch [73/100]\t\n",
      "\tTraining Loss: 35.23541833087802 Test Loss: 35.23541833087802\n",
      "\tTraining Acc: 95.74070458285682 Test Acc: 88.05144309854943\n",
      "\tTime Taken: 0.76384912331899 minutes\n",
      "Epoch [74/100]\t\n",
      "\tTraining Loss: 28.737589279189706 Test Loss: 28.737589279189706\n",
      "\tTraining Acc: 96.56355471256032 Test Acc: 91.1021384776432\n",
      "\tTime Taken: 0.7648616472880045 minutes\n",
      "Epoch [75/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 34.68362946342677 Test Loss: 34.68362946342677\n",
      "\tTraining Acc: 95.82438425706395 Test Acc: 93.25557050994468\n",
      "\tTime Taken: 0.7664235552151998 minutes\n",
      "Epoch [76/100]\t\n",
      "\tTraining Loss: 32.52015259861946 Test Loss: 32.52015259861946\n",
      "\tTraining Acc: 96.0810019246325 Test Acc: 90.95259458651114\n",
      "\tTime Taken: 0.7658773581186931 minutes\n",
      "Epoch [77/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 35.184100802987814 Test Loss: 35.184100802987814\n",
      "\tTraining Acc: 95.71002203564754 Test Acc: 93.86870046358607\n",
      "\tTime Taken: 0.7682293216387431 minutes\n",
      "Epoch [78/100]\t\n",
      "\tTraining Loss: 26.91011975891888 Test Loss: 26.91011975891888\n",
      "\tTraining Acc: 96.74207135086887 Test Acc: 93.061163451473\n",
      "\tTime Taken: 0.7655612111091614 minutes\n",
      "Epoch [79/100]\t\n",
      "\tTraining Loss: 26.873446587473154 Test Loss: 26.873446587473154\n",
      "\tTraining Acc: 96.85364424981172 Test Acc: 92.403170330492\n",
      "\tTime Taken: 0.7655775864919027 minutes\n",
      "Epoch [80/100]\t\n",
      "\tTraining Loss: 35.2759441845119 Test Loss: 35.2759441845119\n",
      "\tTraining Acc: 95.79928035480182 Test Acc: 91.53581576192613\n",
      "\tTime Taken: 0.7656113823254903 minutes\n",
      "Epoch [81/100]\t\n",
      "\tTraining Loss: 32.031773103401065 Test Loss: 32.031773103401065\n",
      "\tTraining Acc: 96.23162533820535 Test Acc: 90.78809630626589\n",
      "\tTime Taken: 0.7657733798027039 minutes\n",
      "Epoch [82/100]\t\n",
      "\tTraining Loss: 34.04894427768886 Test Loss: 34.04894427768886\n",
      "\tTraining Acc: 95.94990376837467 Test Acc: 92.0891281591147\n",
      "\tTime Taken: 0.7656768282254537 minutes\n",
      "Epoch [83/100]\t\n",
      "\tTraining Loss: 25.521913351491094 Test Loss: 25.521913351491094\n",
      "\tTraining Acc: 96.89269476444171 Test Acc: 91.99940182443547\n",
      "\tTime Taken: 0.7654753724733988 minutes\n",
      "Epoch [84/100]\t\n",
      "\tTraining Loss: 24.780402660369873 Test Loss: 24.780402660369873\n",
      "\tTraining Acc: 97.00426766338457 Test Acc: 92.35830716315239\n",
      "\tTime Taken: 0.7658920804659526 minutes\n",
      "Epoch [85/100]\t\n",
      "\tTraining Loss: 23.914934422820807 Test Loss: 23.914934422820807\n",
      "\tTraining Acc: 97.08236869264455 Test Acc: 92.68730372364288\n",
      "\tTime Taken: 0.7648919502894084 minutes\n",
      "Epoch [86/100]\t\n",
      "\tTraining Loss: 28.713079415261745 Test Loss: 28.713079415261745\n",
      "\tTraining Acc: 96.54402945524532 Test Acc: 90.503962913115\n",
      "\tTime Taken: 0.7657360474268595 minutes\n",
      "Epoch [87/100]\t\n",
      "\tTraining Loss: 31.6656972784549 Test Loss: 31.6656972784549\n",
      "\tTraining Acc: 96.1395776965775 Test Acc: 93.04620906235981\n",
      "\tTime Taken: 0.7671800017356872 minutes\n",
      "Epoch [88/100]\t\n",
      "\tTraining Loss: 27.470853709615767 Test Loss: 27.470853709615767\n",
      "\tTraining Acc: 96.81738305765529 Test Acc: 92.79198444743533\n",
      "\tTime Taken: 0.7649690508842468 minutes\n",
      "Epoch [89/100]\t\n",
      "\tTraining Loss: 26.353507816791534 Test Loss: 26.353507816791534\n",
      "\tTraining Acc: 96.93732392401886 Test Acc: 86.0924181247196\n",
      "\tTime Taken: 0.7637356678644817 minutes\n",
      "Epoch [90/100]\t\n",
      "\tTraining Loss: 30.946030113846064 Test Loss: 30.946030113846064\n",
      "\tTraining Acc: 96.33204094725392 Test Acc: 90.13010318528488\n",
      "\tTime Taken: 0.766130272547404 minutes\n",
      "Epoch [91/100]\t\n",
      "\tTraining Loss: 24.328797205351293 Test Loss: 24.328797205351293\n",
      "\tTraining Acc: 97.1353658196424 Test Acc: 93.70420218334081\n",
      "\tTime Taken: 0.7648521145184835 minutes\n",
      "Epoch [92/100]\t\n",
      "\tTraining Loss: 23.835923369042575 Test Loss: 23.835923369042575\n",
      "\tTraining Acc: 97.10189394995956 Test Acc: 91.7750859877374\n",
      "\tTime Taken: 0.766258156299591 minutes\n",
      "Epoch [93/100]\t\n",
      "\tTraining Loss: 20.395472513511777 Test Loss: 20.395472513511777\n",
      "\tTraining Acc: 97.63744386488521 Test Acc: 93.3452968446239\n",
      "\tTime Taken: 0.7651021917661031 minutes\n",
      "Epoch [94/100]\t\n",
      "\tTraining Loss: 21.554796307347715 Test Loss: 21.554796307347715\n",
      "\tTraining Acc: 97.45334858162953 Test Acc: 91.38627187079408\n",
      "\tTime Taken: 0.7649841547012329 minutes\n",
      "Epoch [95/100]\t\n",
      "\tTraining Loss: 22.136390549130738 Test Loss: 22.136390549130738\n",
      "\tTraining Acc: 97.43661264678809 Test Acc: 93.44997756841633\n",
      "\tTime Taken: 0.7653207381566366 minutes\n",
      "Epoch [96/100]\t\n",
      "\tTraining Loss: 29.70349997933954 Test Loss: 29.70349997933954\n",
      "\tTraining Acc: 96.43245655630247 Test Acc: 93.21070734260505\n",
      "\tTime Taken: 0.7651500622431437 minutes\n",
      "Epoch [97/100]\t\n",
      "\tTraining Loss: 20.569723503664136 Test Loss: 20.569723503664136\n",
      "\tTraining Acc: 97.45055925915595 Test Acc: 91.01241214296395\n",
      "\tTime Taken: 0.7653273264567058 minutes\n",
      "Epoch [98/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 21.162073511630297 Test Loss: 21.162073511630297\n",
      "\tTraining Acc: 97.40593009957881 Test Acc: 93.88365485269927\n",
      "\tTime Taken: 0.76630566517512 minutes\n",
      "Epoch [99/100]\t\n",
      "\tTraining Loss: 20.062894612550735 Test Loss: 20.062894612550735\n",
      "\tTraining Acc: 97.76575269866949 Test Acc: 92.68730372364288\n",
      "\tTime Taken: 0.7656510591506958 minutes\n",
      "Epoch [100/100]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/Resnet-18.pt\n",
      "\tTraining Loss: 21.428090495057404 Test Loss: 21.428090495057404\n",
      "\tTraining Acc: 97.45334858162953 Test Acc: 94.37714969343503\n",
      "\tTime Taken: 0.76596999168396 minutes\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs+1):\n",
    "    print(f\"Epoch [{epoch}/{epochs}]\\t\")\n",
    "    stime = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(epoch, model, trainloader, criterion)\n",
    "    test_loss, test_acc = test(epoch, model, testloader, criterion, optimizer, save=True)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"\\tTraining Loss: {train_loss} Test Loss: {test_loss}\")\n",
    "    print(f\"\\tTraining Acc: {train_acc} Test Acc: {test_acc}\")\n",
    "    time_taken = (time.time()-stime)/60\n",
    "    print(f\"\\tTime Taken: {time_taken} minutes\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "clean_test_dataset = torchvision.datasets.CIFAR10(root='D:/Datasets', train=False, download=True, transform=transform_test)\n",
    "testloader_clean = DataLoader(clean_test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "_, c_acc = test(epoch, model, testloader_clean, criterion, optimizer, save=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='D:/Datasets', train=False, download=True)\n",
    "full_poised_test_dataset = PoisonDataset(test_dataset, 0, \"triggers/trigger_white.png\", seed=1, transform=transform_train, poisoning_rate=1.0)\n",
    "testloader_full_poison = DataLoader(full_poised_test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "_, asr = test(epoch, model, testloader_full_poison, criterion, optimizer, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy (C-Acc): 84.16\n",
      "Attack Success Rate (ASR): 9.24\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clean Accuracy (C-Acc): {c_acc}\")\n",
    "print(f\"Attack Success Rate (ASR): {asr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For kNN cleanse with SimCLR_300, we get:\n",
    "\n",
    "    Clean Accuracy (C-Acc): 84.16\n",
    "    Attack Success Rate (ASR): 9.24"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
