{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "from datasets import prepare_poison_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"clean\"  \n",
    "save_name = f\"{DATASET}-cleansed-NEW.pt\"\n",
    "\n",
    "LOAD_CHECKPOINT = False\n",
    "CHECKPOINT = f\"{DATASET}.pt\"\n",
    "\n",
    "TRAIN = True\n",
    "CLEANSE = True\n",
    "CLEANSED_LABELS_NAME = f\"{DATASET}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleansed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleansedDataset(VisionDataset):\n",
    "\n",
    "    def __init__(self, poison_dataset: VisionDataset, cleansed_labels_name: str, transforms: torch.nn.Module = None):\n",
    "        with open(f\"./cleansed_labels/{cleansed_labels_name}.pkl\", 'rb') as f:\n",
    "            predicted_poison = pickle.load(f)\n",
    "\n",
    "        self.data = [poison_dataset[i][0] for i in range(len(poison_dataset)) if not predicted_poison[i]]\n",
    "        self.labels = [poison_dataset[i][1] for i in range(len(poison_dataset)) if not predicted_poison[i]]\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transforms:\n",
    "            item = self.transforms(item)\n",
    "\n",
    "        return item, label\n",
    "\n",
    "\n",
    "class SkipLabelDataset(VisionDataset):\n",
    "\n",
    "    def __init__(self, original_dataset: VisionDataset, skip_class: int):\n",
    "        self.return_as_pil = type(original_dataset[0][0]) is Image.Image\n",
    "\n",
    "        targets = np.array(original_dataset.targets)\n",
    "        self.data = original_dataset.data[targets != skip_class]\n",
    "        self.targets = targets[targets != skip_class].tolist()\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data = self.data[index]\n",
    "        target = self.targets[index]\n",
    "\n",
    "        if self.return_as_pil:\n",
    "            data = Image.fromarray(data)\n",
    "        \n",
    "        return data, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ProbTransform(torch.nn.Module):\n",
    "    def __init__(self, f, p=1):\n",
    "        super(ProbTransform, self).__init__()\n",
    "        self.f = f\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if random.random() < self.p:\n",
    "            return self.f(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    ProbTransform(transforms.RandomCrop(32, padding=5), p=0.8),\n",
    "    ProbTransform(transforms.transforms.RandomRotation(10), p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_poison_dataset, _, target_class, train_dataset = prepare_poison_dataset(DATASET, train=True, transform=transform_train, return_original_label=False)\n",
    "if CLEANSE:\n",
    "    train_poison_dataset = CleansedDataset(train_poison_dataset, CLEANSED_LABELS_NAME + \"-train\")\n",
    "trainloader = DataLoader(train_poison_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "test_poison_dataset, _, _, test_dataset = prepare_poison_dataset(DATASET, train=False, transform=transform_test, return_original_label=False)\n",
    "if CLEANSE:\n",
    "    test_poison_dataset = CleansedDataset(test_poison_dataset, CLEANSED_LABELS_NAME + \"-test\")\n",
    "testloader = DataLoader(test_poison_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a PreAct-Resnet-18 classifier on the cleansed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActBlock(nn.Module):\n",
    "    \"\"\"Pre-activation version of the BasicBlock.\"\"\"\n",
    "\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.ind = None\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, \"shortcut\") else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        if self.ind is not None:\n",
    "            out += shortcut[:, self.ind, :, :]\n",
    "        else:\n",
    "            out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActBottleneck(nn.Module):\n",
    "    \"\"\"Pre-activation version of the original Bottleneck module.\"\"\"\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, \"shortcut\") else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = self.conv3(F.relu(self.bn3(out)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def PreActResNet18(num_classes=10):\n",
    "    return PreActResNet(PreActBlock, [2, 2, 2, 2], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, epoch, name):\n",
    "    out = os.path.join('./saved_models/preact-resnet18', name)\n",
    "\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'epoch': epoch\n",
    "                }, out)\n",
    "\n",
    "    print(f\"\\tSaved model, optimizer, scheduler and epoch info to {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PreActResNet18()\n",
    "model.to(device)\n",
    "\n",
    "epochs = 35\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [100,200,300,400], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "\n",
    "if LOAD_CHECKPOINT:\n",
    "    out = os.path.join('./saved_models/preact-resnet18/', CHECKPOINT)\n",
    "    checkpoint = torch.load(out, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "\n",
    "    print(\"Loaded checkpoint\")\n",
    "    print(f\"{start_epoch = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, dataloader, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for _, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        if len(targets.shape)>1:\n",
    "            targets = targets.squeeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    return train_loss, acc\n",
    "\n",
    "def test(epoch, model, dataloader, criterion, optimizer, save=False):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            if len(targets.shape)>1:\n",
    "                targets = targets.squeeze(1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        if save: save_model(model, optimizer, scheduler, epoch, save_name)\n",
    "        best_acc = acc\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 385.95033502578735 Test Loss: 63.4105087518692\n",
      "\tTraining Acc: 50.92301009881638 Test Acc: 66.09848484848484\n",
      "\tTime Taken: 0.46016952594121296 minutes\n",
      "Epoch [2/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 218.795134216547 Test Loss: 49.72550308704376\n",
      "\tTraining Acc: 73.28428711043544 Test Acc: 73.3495670995671\n",
      "\tTime Taken: 0.43224647839864094 minutes\n",
      "Epoch [3/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 148.41328141093254 Test Loss: 40.06795582175255\n",
      "\tTraining Acc: 81.94972309697036 Test Acc: 78.39556277056278\n",
      "\tTime Taken: 0.44717613061269124 minutes\n",
      "Epoch [4/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 107.49517008662224 Test Loss: 28.323986381292343\n",
      "\tTraining Acc: 87.16473015528288 Test Acc: 84.3073593073593\n",
      "\tTime Taken: 0.4279632369677226 minutes\n",
      "Epoch [5/35]\t\n",
      "\tTraining Loss: 76.55592560768127 Test Loss: 36.78856697678566\n",
      "\tTraining Acc: 90.76989901183624 Test Acc: 81.61525974025975\n",
      "\tTime Taken: 0.4267132560412089 minutes\n",
      "Epoch [6/35]\t\n",
      "\tTraining Loss: 57.81265124678612 Test Loss: 36.57931238412857\n",
      "\tTraining Acc: 92.99869692691932 Test Acc: 82.34577922077922\n",
      "\tTime Taken: 0.4312460819880168 minutes\n",
      "Epoch [7/35]\t\n",
      "\tTraining Loss: 41.108905635774136 Test Loss: 58.47809571027756\n",
      "\tTraining Acc: 95.05103702899338 Test Acc: 77.16450216450217\n",
      "\tTime Taken: 0.45296873648961383 minutes\n",
      "Epoch [8/35]\t\n",
      "\tTraining Loss: 33.71590035222471 Test Loss: 44.2212298810482\n",
      "\tTraining Acc: 95.83559561298729 Test Acc: 83.27922077922078\n",
      "\tTime Taken: 0.4049805760383606 minutes\n",
      "Epoch [9/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 27.78401963878423 Test Loss: 39.02762794494629\n",
      "\tTraining Acc: 96.65816049516778 Test Acc: 85.17316017316017\n",
      "\tTime Taken: 0.40465907255808514 minutes\n",
      "Epoch [10/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 17.284314575605094 Test Loss: 37.66234731674194\n",
      "\tTraining Acc: 97.88250624389184 Test Acc: 86.3771645021645\n",
      "\tTime Taken: 0.40497164726257323 minutes\n",
      "Epoch [11/35]\t\n",
      "\tTraining Loss: 21.703016283921897 Test Loss: 35.1110085695982\n",
      "\tTraining Acc: 97.35041806928005 Test Acc: 86.06601731601732\n",
      "\tTime Taken: 0.4040301283200582 minutes\n",
      "Epoch [12/35]\t\n",
      "\tTraining Loss: 12.993538102135062 Test Loss: 40.529249012470245\n",
      "\tTraining Acc: 98.45531545227495 Test Acc: 85.83603896103897\n",
      "\tTime Taken: 0.4154972434043884 minutes\n",
      "Epoch [13/35]\t\n",
      "\tTraining Loss: 12.190345216542482 Test Loss: 40.575965493917465\n",
      "\tTraining Acc: 98.50418069280052 Test Acc: 85.82251082251082\n",
      "\tTime Taken: 0.4176466544469198 minutes\n",
      "Epoch [14/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 7.632532698567957 Test Loss: 34.493124172091484\n",
      "\tTraining Acc: 99.12042567053969 Test Acc: 87.77056277056278\n",
      "\tTime Taken: 0.4122249484062195 minutes\n",
      "Epoch [15/35]\t\n",
      "\tTraining Loss: 6.461238652584143 Test Loss: 36.375604793429375\n",
      "\tTraining Acc: 99.29416874796395 Test Acc: 87.70292207792208\n",
      "\tTime Taken: 0.39327557881673175 minutes\n",
      "Epoch [16/35]\t\n",
      "\tTraining Loss: 8.864739582175389 Test Loss: 38.27290706336498\n",
      "\tTraining Acc: 98.95211206428493 Test Acc: 87.37824675324676\n",
      "\tTime Taken: 0.39307891527811684 minutes\n",
      "Epoch [17/35]\t\n",
      "\tTraining Loss: 7.595382109167986 Test Loss: 42.246066838502884\n",
      "\tTraining Acc: 99.08241937235313 Test Acc: 86.56655844155844\n",
      "\tTime Taken: 0.40442902247111 minutes\n",
      "Epoch [18/35]\t\n",
      "\tTraining Loss: 8.922000371385366 Test Loss: 43.93293088674545\n",
      "\tTraining Acc: 98.94125312194592 Test Acc: 86.07954545454545\n",
      "\tTime Taken: 0.40113017956415814 minutes\n",
      "Epoch [19/35]\t\n",
      "\tTraining Loss: 6.562407968682237 Test Loss: 42.15952533483505\n",
      "\tTraining Acc: 99.25073297860789 Test Acc: 86.40422077922078\n",
      "\tTime Taken: 0.41258177359898884 minutes\n",
      "Epoch [20/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 4.108653333038092 Test Loss: 27.774412274360657\n",
      "\tTraining Acc: 99.57107177760886 Test Acc: 90.21915584415585\n",
      "\tTime Taken: 0.39002455870310465 minutes\n",
      "Epoch [21/35]\t\n",
      "\tTraining Loss: 2.9385413957643323 Test Loss: 38.40229296684265\n",
      "\tTraining Acc: 99.67423172982951 Test Acc: 87.75703463203463\n",
      "\tTime Taken: 0.39754833380381266 minutes\n",
      "Epoch [22/35]\t\n",
      "\tTraining Loss: 2.765924784966046 Test Loss: 38.92331720888615\n",
      "\tTraining Acc: 99.72038223477033 Test Acc: 88.00054112554112\n",
      "\tTime Taken: 0.406930156548818 minutes\n",
      "Epoch [23/35]\t\n",
      "\tTraining Loss: 3.2365722183603793 Test Loss: 34.310683354735374\n",
      "\tTraining Acc: 99.64708437398197 Test Acc: 88.56872294372295\n",
      "\tTime Taken: 0.39540680646896365 minutes\n",
      "Epoch [24/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 1.6904329308163142 Test Loss: 28.270856961607933\n",
      "\tTraining Acc: 99.8289716581605 Test Acc: 90.23268398268398\n",
      "\tTime Taken: 0.4138634284337362 minutes\n",
      "Epoch [25/35]\t\n",
      "\tTraining Loss: 1.012320123205427 Test Loss: 30.28890712559223\n",
      "\tTraining Acc: 99.9049842545336 Test Acc: 89.81331168831169\n",
      "\tTime Taken: 0.40771623849868777 minutes\n",
      "Epoch [26/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 0.6095906781483791 Test Loss: 25.44140462577343\n",
      "\tTraining Acc: 99.9592789662287 Test Acc: 90.88203463203463\n",
      "\tTime Taken: 0.4364869157473246 minutes\n",
      "Epoch [27/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 0.12836167101340834 Test Loss: 24.84660615026951\n",
      "\tTraining Acc: 100.0 Test Acc: 91.08495670995671\n",
      "\tTime Taken: 0.4300082564353943 minutes\n",
      "Epoch [28/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 0.15268214468233055 Test Loss: 24.190549589693546\n",
      "\tTraining Acc: 99.99728526441524 Test Acc: 91.13906926406926\n",
      "\tTime Taken: 0.4167670567830404 minutes\n",
      "Epoch [29/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 0.11922785968636163 Test Loss: 23.499031849205494\n",
      "\tTraining Acc: 99.99728526441524 Test Acc: 91.51785714285714\n",
      "\tTime Taken: 0.39252870877583823 minutes\n",
      "Epoch [30/35]\t\n",
      "\tTraining Loss: 0.10327029784093611 Test Loss: 22.62668129056692\n",
      "\tTraining Acc: 100.0 Test Acc: 91.28787878787878\n",
      "\tTime Taken: 0.413330602645874 minutes\n",
      "Epoch [31/35]\t\n",
      "\tTraining Loss: 0.08613406326185213 Test Loss: 22.310918606817722\n",
      "\tTraining Acc: 100.0 Test Acc: 91.23376623376623\n",
      "\tTime Taken: 0.4064026713371277 minutes\n",
      "Epoch [32/35]\t\n",
      "\tTraining Loss: 0.09332585873926291 Test Loss: 21.676078230142593\n",
      "\tTraining Acc: 100.0 Test Acc: 91.51785714285714\n",
      "\tTime Taken: 0.39622753063837685 minutes\n",
      "Epoch [33/35]\t\n",
      "\tTraining Loss: 0.0976746719534276 Test Loss: 21.30698649585247\n",
      "\tTraining Acc: 100.0 Test Acc: 91.46374458874459\n",
      "\tTime Taken: 0.41924638748168946 minutes\n",
      "Epoch [34/35]\t\n",
      "\tTraining Loss: 0.11012083559762686 Test Loss: 20.77769909799099\n",
      "\tTraining Acc: 100.0 Test Acc: 91.51785714285714\n",
      "\tTime Taken: 0.3901971181233724 minutes\n",
      "Epoch [35/35]\t\n",
      "\tSaved model, optimizer, scheduler and epoch info to ./saved_models/preact-resnet18\\clean-cleansed-NEW.pt\n",
      "\tTraining Loss: 0.10364511936495546 Test Loss: 20.553191900253296\n",
      "\tTraining Acc: 100.0 Test Acc: 91.54491341991341\n",
      "\tTime Taken: 0.39756351709365845 minutes\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    for epoch in range(start_epoch, epochs+1):\n",
    "        print(f\"Epoch [{epoch}/{epochs}]\\t\")\n",
    "        stime = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(epoch, model, trainloader, criterion)\n",
    "        test_loss, test_acc = test(epoch, model, testloader, criterion, optimizer, save=True)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"\\tTraining Loss: {train_loss} Test Loss: {test_loss}\")\n",
    "        print(f\"\\tTraining Acc: {train_acc} Test Acc: {test_acc}\")\n",
    "        time_taken = (time.time()-stime)/60\n",
    "        print(f\"\\tTime Taken: {time_taken} minutes\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    # loading the best model checkpoint from training before testing\n",
    "    out = os.path.join('./saved_models/preact-resnet18/', save_name)\n",
    "    checkpoint = torch.load(out, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "transform_clean = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_poison = transforms.Compose([\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "clean_test_dataset = torchvision.datasets.CIFAR10(root='C:/Datasets', train=False, download=False, transform=transform_clean)\n",
    "testloader_clean = DataLoader(clean_test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "_, c_acc = test(0, model, testloader_clean, criterion, optimizer, save=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='C:/Datasets', train=False, download=False)\n",
    "test_dataset = SkipLabelDataset(test_dataset, target_class)\n",
    "full_poisoned_test_dataset, _, _, _ = prepare_poison_dataset(DATASET, train=False, transform=transform_poison, return_original_label=False, clean_dataset=test_dataset, full_poison=True)\n",
    "\n",
    "testloader_full_poison = DataLoader(full_poisoned_test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "_, asr = test(0, model, testloader_full_poison, criterion, optimizer, save=False)\n",
    "\n",
    "# note: The reason for mismatch between c_acc displayed here and test accuracy displayed during\n",
    "# training is that test accuracy is calculated on a cleaned dataset, ie. it is missing about 25%\n",
    "# of data. SimCLR has probably filtered out \"hard\" examples, which are much different than other\n",
    "# examples of the same class, so when added to the test dataset at the end here they bring down\n",
    "# the accuracy a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy (C-Acc): 77.61\n",
      "Attack Success Rate (ASR): 77.61\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"Clean Accuracy (C-Acc): {c_acc}\")\n",
    "print(f\"Attack Success Rate (ASR): {asr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    No attack\n",
    "    Clean Accuracy (C-Acc): 91.07\n",
    "    Attack Success Rate (ASR): 91.07\n",
    "\n",
    "    Badnets1-0\n",
    "    Clean Accuracy (C-Acc): 90.85\n",
    "    Attack Success Rate (ASR): 98.65555555555555\n",
    "\n",
    "    Badnets1-1\n",
    "    Clean Accuracy (C-Acc): 91.18\n",
    "    Attack Success Rate (ASR): 95.54444444444445\n",
    "\n",
    "    Badnets1-2\n",
    "    Clean Accuracy (C-Acc): 90.84\n",
    "    Attack Success Rate (ASR): 91.63333333333334\n",
    "\n",
    "    Badnets10-0\n",
    "    Clean Accuracy (C-Acc): 90.79\n",
    "    Attack Success Rate (ASR): 99.9888888888889\n",
    "\n",
    "    Badnets10-1\n",
    "    Clean Accuracy (C-Acc): 90.71\n",
    "    Attack Success Rate (ASR): 99.93333333333334\n",
    "\n",
    "    Badnets10-2\n",
    "    Clean Accuracy (C-Acc): 89.94\n",
    "    Attack Success Rate (ASR): 99.9888888888889\n",
    "\n",
    "    SIG-0\n",
    "    Clean Accuracy (C-Acc): 91.31\n",
    "    Attack Success Rate (ASR): 100.0\n",
    "\n",
    "    SIG-1\n",
    "    Clean Accuracy (C-Acc): 91.0\n",
    "    Attack Success Rate (ASR): 99.61111111111111\n",
    "\n",
    "    SIG-2\n",
    "    Clean Accuracy (C-Acc): 91.39\n",
    "    Attack Success Rate (ASR): 99.9888888888889\n",
    "\n",
    "    WaNet0\n",
    "    Clean Accuracy (C-Acc): 87.25\n",
    "    Attack Success Rate (ASR): 95.5\n",
    "\n",
    "    WaNet1\n",
    "    Clean Accuracy (C-Acc): 89.14\n",
    "    Attack Success Rate (ASR): 91.53333333333333\n",
    "\n",
    "    WaNet2\n",
    "    Clean Accuracy (C-Acc): 88.26\n",
    "    Attack Success Rate (ASR): 93.3\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "    WITH OUR DEFENSE:\n",
    "\n",
    "    Badnets1-0\n",
    "    Clean Accuracy (C-Acc): 78.45\n",
    "    Attack Success Rate (ASR): 3.1666666666666665\n",
    "\n",
    "    Badnets1-1\n",
    "    Clean Accuracy (C-Acc): 77.65\n",
    "    Attack Success Rate (ASR): 1.5444444444444445\n",
    "\n",
    "    Badnets1-2\n",
    "    Clean Accuracy (C-Acc): 81.88\n",
    "    Attack Success Rate (ASR): 2.0\n",
    "\n",
    "    Badnets10-0\n",
    "    Clean Accuracy (C-Acc): 76.86\n",
    "    Attack Success Rate (ASR): 4.088888888888889\n",
    "\n",
    "    Badnets10-1\n",
    "    Clean Accuracy (C-Acc): 77.52\n",
    "    Attack Success Rate (ASR): 0.3111111111111111\n",
    "\n",
    "    Badnets10-2\n",
    "    Clean Accuracy (C-Acc): 76.43\n",
    "    Attack Success Rate (ASR): 3.4\n",
    "\n",
    "    SIG-0\n",
    "    Clean Accuracy (C-Acc): 82.16\n",
    "    Attack Success Rate (ASR): 0.0\n",
    "\n",
    "    SIG-1\n",
    "    Clean Accuracy (C-Acc): 84.0\n",
    "    Attack Success Rate (ASR): 0.0\n",
    "\n",
    "    SIG-2\n",
    "    Clean Accuracy (C-Acc): 83.99\n",
    "    Attack Success Rate (ASR): 0.6444444444444445\n",
    "\n",
    "    WaNet0\n",
    "    Clean Accuracy (C-Acc): 79.48\n",
    "    Attack Success Rate (ASR): 3.7444444444444445\n",
    "\n",
    "    WaNet1\n",
    "    Clean Accuracy (C-Acc): 81.71\n",
    "    Attack Success Rate (ASR): 1.3\n",
    "\n",
    "    WaNet2\n",
    "    Clean Accuracy (C-Acc): 81.47\n",
    "    Attack Success Rate (ASR): 5.266666666666667"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
