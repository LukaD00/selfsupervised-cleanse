{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from datasets import BadNetsDataset, WaNetDataset, SIGDataset\n",
    "from simclr import SimClrBackbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TSNE = False\n",
    "RUN_KNN = False\n",
    "RUN_ENERGY = True\n",
    "RUN_LOGREG = False\n",
    "\n",
    "SIMCLR_MODEL_NAME = \"BadNets-SimCLR.pt\"\n",
    "\n",
    "DATASET = \"badnets\"\n",
    "TRAIN = True\n",
    "\n",
    "if DATASET == \"badnets\":\n",
    "    TARGET_CLASS = 1\n",
    "    DATASET_NAME = \"BadNets\"\n",
    "elif DATASET == \"wanet\":\n",
    "    TARGET_CLASS = 0\n",
    "    DATASET_NAME = \"WaNet\"\n",
    "elif DATASET == \"sig\":\n",
    "    TARGET_CLASS = 0\n",
    "    DATASET_NAME = \"SIG\"\n",
    "else:\n",
    "    raise Exception(\"Invalid dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poison dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root='C:/Datasets', train=TRAIN)\n",
    "\n",
    "if DATASET == \"badnets\":\n",
    "    poison_dataset = BadNetsDataset(dataset, TARGET_CLASS, \"triggers/trigger_10.png\", seed=1)\n",
    "elif DATASET == \"wanet\":\n",
    "    poison_dataset = WaNetDataset(dataset, TARGET_CLASS, seed=1)\n",
    "elif DATASET == \"sig\":\n",
    "    poison_dataset = SIGDataset(dataset, TARGET_CLASS, 20, 6, seed=1)\n",
    "else:\n",
    "    raise Exception(\"Invalid dataset\")\n",
    "\n",
    "dataloader = DataLoader(poison_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Luka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimClrBackbone(\n",
       "  (pretrained): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projector): ProjectionHead(\n",
       "    (layers): Sequential(\n",
       "      (0): LinearLayer(\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): LinearLayer(\n",
       "        (linear): Linear(in_features=512, out_features=128, bias=False)\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimClrBackbone()\n",
    "\n",
    "out = os.path.join('./saved_models/', SIMCLR_MODEL_NAME)\n",
    "checkpoint = torch.load(out, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = None\n",
    "labels_poison = None\n",
    "labels_true = None\n",
    "\n",
    "for i, (img, labels_batch_poison, labels_batch_true) in enumerate(dataloader):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features_batch = model(img.to(device)).cpu().data.numpy()\n",
    "        \n",
    "    if features is None:\n",
    "        features = features_batch\n",
    "        labels_poison = labels_batch_poison\n",
    "        labels_true = labels_batch_true\n",
    "    else:\n",
    "        features = np.append(features, features_batch, axis=0)\n",
    "        labels_poison = np.append(labels_poison, labels_batch_poison, axis=0)\n",
    "        labels_true = np.append(labels_true, labels_batch_true, axis=0)\n",
    "\n",
    "num_classes = max(labels_poison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot t-SNE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TSNE:\n",
    "\n",
    "    # label poison examples as 10\n",
    "    labels = labels_true[:]\n",
    "    labels[[poison_dataset.is_poison(i) for i in range(len(labels))]] = 10\n",
    "\n",
    "    # Plot only a subset\n",
    "    subset_size = 10000\n",
    "    features_subset = features[:subset_size]\n",
    "    labels_subset = labels[:subset_size]\n",
    "        \n",
    "    tsne = TSNE(n_components = 2, perplexity = 50)\n",
    "    tsne_features = tsne.fit_transform(features_subset)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        plt.scatter(tsne_features[labels_subset==i,1], tsne_features[labels_subset==i,0])\n",
    "    plt.scatter(tsne_features[labels_subset==10,1], tsne_features[labels_subset==10,0], c = \"black\", marker= \"x\")\n",
    "\n",
    "    plt.legend([str(i) for i in range(num_classes)] + [\"poison\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_KNN:\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    examples_per_class = len(dataset) / num_classes\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=int(examples_per_class/2))\n",
    "    knn.fit(features, labels_poison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_KNN:\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    predicted_labels = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        feature = features[i]\n",
    "        poison_label = labels_poison[i]\n",
    "        true_label = labels_true[i]\n",
    "        predicted_label = knn.predict(np.expand_dims(feature,0))[0]\n",
    "\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "        true_poison = poison_dataset.is_poison(i)\n",
    "        predicted_poison = poison_label != predicted_label\n",
    "\n",
    "        if true_poison and predicted_poison:\n",
    "            tp += 1\n",
    "        elif not true_poison and predicted_poison:\n",
    "            fp += 1\n",
    "        elif true_poison and not predicted_poison:\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"{i} / {len(dataset)}\")\n",
    "            print(f\"\\t {tp} \\t {fp}\")\n",
    "            print(f\"\\t {fn} \\t {tn}\")\n",
    "\n",
    "            fnr = fn/(fn+tp) if fn+tp!=0 else 0\n",
    "            tnr = tn/(tn+fp) if tn+fp!=0 else 0\n",
    "            poison_rate = fn/(fn+tn) if fn+tn!=0 else 0\n",
    "            print(f\"Percentage of poisoned images (out of all poisoned) kept: {100*fnr: .2f}%\")\n",
    "            print(f\"Percentage of clean images (out of all clean) kept: {100*tnr: .2f}%\")\n",
    "            print(f\"Percentage of remaining poisoned images (out of all remaining): {100*poison_rate: .2f}%\")\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{len(dataset)} / {len(dataset)}\")\n",
    "    print(f\"\\t {tp} \\t {fp}\")\n",
    "    print(f\"\\t {fn} \\t {tn}\")\n",
    "\n",
    "    fnr = fn/(fn+tp) if fn+tp!=0 else 0\n",
    "    tnr = tn/(tn+fp) if tn+fp!=0 else 0\n",
    "    poison_rate = fn/(fn+tn) if fn+tn!=0 else 0\n",
    "    print(f\"Percentage of poisoned images (out of all poisoned) kept: {100*fnr: .2f}%\")\n",
    "    print(f\"Percentage of clean images (out of all clean) kept: {100*tnr: .2f}%\")\n",
    "    print(f\"Percentage of remaining poisoned images (out of all remaining): {100*poison_rate: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "\n",
    "CIFAR-10 train \\\n",
    "BadNets \n",
    "\n",
    "    50000 / 50000\n",
    "        4905 \t 9481\n",
    "        95 \t 35519\n",
    "    Percentage of poisoned images (out of all poisoned) kept:  1.90%\n",
    "    Percentage of clean images (out of all clean) kept:  78.93%\n",
    "    Percentage of remaining poisoned images (out of all remaining):  0.27%\n",
    "\n",
    "CIFAR-10 test \\\n",
    "BadNets \n",
    "\n",
    "    10000 / 10000\n",
    "        960 \t 2056\n",
    "        40 \t 6944\n",
    "    Percentage of poisoned images (out of all poisoned) kept:  4.00%\n",
    "    Percentage of clean images (out of all clean) kept:  77.16%\n",
    "    Percentage of remaining poisoned images (out of all remaining):  0.57%\n",
    "\n",
    "------------------------------------\n",
    "\n",
    "CIFAR-10 train \\\n",
    "WaNet \n",
    "\n",
    "    50000 / 50000\n",
    "        3975 \t 14331\n",
    "        1025 \t 30669\n",
    "    Percentage of poisoned images (out of all poisoned) kept:  20.50%\n",
    "    Percentage of clean images (out of all clean) kept:  68.15%\n",
    "    Percentage of remaining poisoned images (out of all remaining):  3.23%\n",
    "\n",
    "CIFAR-10 test \\\n",
    "WaNet \n",
    "\n",
    "    10000 / 10000\n",
    "        712 \t 3058\n",
    "        288 \t 5942\n",
    "    Percentage of poisoned images (out of all poisoned) kept:  28.80%\n",
    "    Percentage of clean images (out of all clean) kept:  66.02%\n",
    "    Percentage of remaining poisoned images (out of all remaining):  4.62%\n",
    "\n",
    "------------------------------------\n",
    "\n",
    "CIFAR-10 test \\\n",
    "SIG\n",
    "\n",
    "    50000 / 50000\n",
    "        0 \t 9195\n",
    "        500 \t 40305\n",
    "    Percentage of poisoned images (out of all poisoned) kept:  100.00%\n",
    "    Percentage of clean images (out of all clean) kept:  81.42%\n",
    "    Percentage of remaining poisoned images (out of all remaining):  1.23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_KNN:\n",
    "\n",
    "    save_name = f\"__NEW__{DATASET_NAME}-kNN-{'train' if TRAIN else 'test'}\"\n",
    "\n",
    "    with open(f\"./cleansed_labels/{save_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(predicted_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyClassifier():\n",
    "\n",
    "    def __init__(self, t=1):\n",
    "        self.t = t\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.C = np.max(y)\n",
    "        self.Ic = {c:[i for i in range(len(y)) if y[i]==c] for c in range(self.C)}\n",
    "        \n",
    "    def predict_index(self, i):\n",
    "        xi = self.X[i]\n",
    "\n",
    "        exp_all = np.exp([xi*self.X[k]/self.t for k in range(len(self.X))])\n",
    "        sum_exp_all_except_xi = np.sum([exp_all[k] for k in range(len(self.X)) if k!=i])\n",
    "        mean_exp_c = [np.mean([exp_all[k] for k in self.Ic[c] if k!=i]) for c in range(self.C)]\n",
    "    \n",
    "        Scs = mean_exp_c / sum_exp_all_except_xi\n",
    "        return np.argmax(Scs)\n",
    "\n",
    "if DATASET == \"badnets\":\n",
    "    T = 100\n",
    "elif DATASET == \"wanet\":\n",
    "    T = 10\n",
    "elif DATASET == \"sig\":\n",
    "    T = 1\n",
    "else:\n",
    "    raise Exception(\"Invalid dataset\")\n",
    "\n",
    "if RUN_ENERGY:\n",
    "    energy = EnergyClassifier(t=T)\n",
    "    energy.fit(features, labels_poison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 / 50000\n",
      "\t 4618 \t 12732\n",
      "\t 382 \t 32268\n",
      "Percentage of poisoned images (out of all poisoned) kept:  7.64%\n",
      "Percentage of clean images (out of all clean) kept:  71.71%\n",
      "Percentage of remaining poisoned images (out of all remaining):  1.17%\n"
     ]
    }
   ],
   "source": [
    "if RUN_ENERGY:\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    predicted_labels = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        poison_label = labels_poison[i]\n",
    "        true_label = labels_true[i]\n",
    "        predicted_label = energy.predict_index(i)\n",
    "\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "        true_poison = poison_dataset.is_poison(i)\n",
    "        predicted_poison = poison_label != predicted_label\n",
    "\n",
    "        if true_poison and predicted_poison:\n",
    "            tp += 1\n",
    "        elif not true_poison and predicted_poison:\n",
    "            fp += 1\n",
    "        elif true_poison and not predicted_poison:\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"{i} / {len(dataset)}\")\n",
    "            print(f\"\\t {tp} \\t {fp}\")\n",
    "            print(f\"\\t {fn} \\t {tn}\")\n",
    "\n",
    "            fnr = fn/(fn+tp) if fn+tp!=0 else 0\n",
    "            tnr = tn/(tn+fp) if tn+fp!=0 else 0\n",
    "            poison_rate = fn/(fn+tn) if fn+tn!=0 else 0\n",
    "            print(f\"Percentage of poisoned images (out of all poisoned) kept: {100*fnr: .2f}%\")\n",
    "            print(f\"Percentage of clean images (out of all clean) kept: {100*tnr: .2f}%\")\n",
    "            print(f\"Percentage of remaining poisoned images (out of all remaining): {100*poison_rate: .2f}%\")\n",
    "\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{len(dataset)} / {len(dataset)}\")\n",
    "    print(f\"\\t {tp} \\t {fp}\")\n",
    "    print(f\"\\t {fn} \\t {tn}\")\n",
    "\n",
    "    fnr = fn/(fn+tp) if fn+tp!=0 else 0\n",
    "    tnr = tn/(tn+fp) if tn+fp!=0 else 0\n",
    "    poison_rate = fn/(fn+tn) if fn+tn!=0 else 0\n",
    "    print(f\"Percentage of poisoned images (out of all poisoned) kept: {100*fnr: .2f}%\")\n",
    "    print(f\"Percentage of clean images (out of all clean) kept: {100*tnr: .2f}%\")\n",
    "    print(f\"Percentage of remaining poisoned images (out of all remaining): {100*poison_rate: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 train \\\n",
    "BadNets\n",
    "\n",
    "\t50000 / 50000\n",
    "\t\t4618 \t 12732\n",
    "\t\t382 \t 32268\n",
    "\tPercentage of poisoned images (out of all poisoned) kept:  7.64%\n",
    "\tPercentage of clean images (out of all clean) kept:  71.71%\n",
    "\tPercentage of remaining poisoned images (out of all remaining):  1.17%\n",
    "\n",
    "CIFAR-10 test \\\n",
    "BadNets\n",
    "\n",
    "\t10000 / 10000\n",
    "\t\t920 \t 2585\n",
    "\t\t80 \t 6415\n",
    "\tPercentage of poisoned images (out of all poisoned) kept:  8.00%\n",
    "\tPercentage of clean images (out of all clean) kept:  71.28%\n",
    "\tPercentage of remaining poisoned images (out of all remaining):  1.23%\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "CIFAR-10 train \\\n",
    "WaNet\n",
    "\n",
    "\t50000 / 50000\n",
    "\t\t4725 \t 14096\n",
    "\t\t275 \t 30904\n",
    "\tPercentage of poisoned images (out of all poisoned) kept:  5.50%\n",
    "\tPercentage of clean images (out of all clean) kept:  68.68%\n",
    "\tPercentage of remaining poisoned images (out of all remaining):  0.88%\n",
    "\n",
    "CIFAR-10 test \\\n",
    "WaNet\n",
    "\n",
    "\t10000 / 10000\n",
    "\t\t951 \t 2851\n",
    "\t\t49 \t 6149\n",
    "\tPercentage of poisoned images (out of all poisoned) kept:  4.90%\n",
    "\tPercentage of clean images (out of all clean) kept:  68.32%\n",
    "\tPercentage of remaining poisoned images (out of all remaining):  0.79%\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "CIFAR-10 train \\\n",
    "SIG\n",
    "\n",
    "\t50000 / 50000\n",
    "\t\t2 \t 15777\n",
    "\t\t498 \t 33723\n",
    "\tPercentage of poisoned images (out of all poisoned) kept:  99.60%\n",
    "\tPercentage of clean images (out of all clean) kept:  68.13%\n",
    "\tPercentage of remaining poisoned images (out of all remaining):  1.46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ENERGY:\n",
    "\n",
    "    save_name = f\"__NEW__{DATASET_NAME}-Energy-{'train' if TRAIN else 'test'}\"\n",
    "\n",
    "    with open(f\"./cleansed_labels/{save_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(predicted_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(LogReg, self).__init__()\n",
    "        self.linear = torch.nn.Linear(n_inputs, n_outputs)\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if RUN_LOGREG:\n",
    "    labels_poison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
